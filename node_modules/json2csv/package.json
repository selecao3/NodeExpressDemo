{
  "_from": "json2csv@^4.3.2",
  "_id": "json2csv@4.3.2",
  "_inBundle": false,
  "_integrity": "sha512-xxike2yVqWUrxchIg2BS1hLaXDwInEU0u+aQQ4KfEXF5y+ZdEhH7pn23wCWL1rsCYM7OzgBRAxuo0qUzCgfJ9g==",
  "_location": "/json2csv",
  "_phantomChildren": {},
  "_requested": {
    "escapedName": "json2csv",
    "fetchSpec": "^4.3.2",
    "name": "json2csv",
    "raw": "json2csv@^4.3.2",
    "rawSpec": "^4.3.2",
    "registry": true,
    "saveSpec": null,
    "type": "range"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/json2csv/-/json2csv-4.3.2.tgz",
  "_shasum": "e766b5a81d408087ae25a72989cd8217641aa126",
  "_shrinkwrap": null,
  "_spec": "json2csv@^4.3.2",
  "_where": "C:\\Users\\kazuha\\develop\\Node\\node_demo01",
  "author": {
    "email": "mirco.zeiss@gmail.com",
    "name": "Mirco Zeiss"
  },
  "bin": {
    "json2csv": "./bin/json2csv.js"
  },
  "browser": "dist/json2csv.umd.js",
  "bugs": {
    "url": "https://github.com/zemirco/json2csv/issues"
  },
  "bundleDependencies": false,
  "dependencies": {
    "commander": "^2.15.1",
    "jsonparse": "^1.3.1",
    "lodash.get": "^4.4.2",
    "lodash.set": "^4.3.2"
  },
  "deprecated": false,
  "description": "Convert JSON to CSV",
  "devDependencies": {
    "babel-core": "^6.26.3",
    "babel-preset-es2015-rollup": "^3.0.0",
    "coveralls": "^3.0.1",
    "docpress": "^0.7.1",
    "eslint": "^5.0.1",
    "gh-pages": "^2.0.1",
    "in-publish": "^2.0.0",
    "nyc": "^12.0.2",
    "rollup": "^0.62.0",
    "rollup-plugin-babel": "^3.0.5",
    "rollup-plugin-commonjs": "^9.1.3",
    "rollup-plugin-node-builtins": "^2.1.2",
    "rollup-plugin-node-globals": "^1.2.1",
    "rollup-plugin-node-resolve": "^3.3.0",
    "standard-version": "^4.4.0",
    "tap-spec": "^5.0.0",
    "tape": "^4.9.1"
  },
  "homepage": "https://github.com/zemirco/json2csv#readme",
  "keywords": [
    "convert",
    "csv",
    "export",
    "json",
    "parse",
    "to"
  ],
  "license": "MIT",
  "main": "dist/json2csv.cjs.js",
  "module": "dist/json2csv.esm.js",
  "name": "json2csv",
  "optionalDependencies": {},
  "preferGlobal": "true",
  "readme": "# json2csv\n\nConverts json into csv with column titles and proper line endings.  \nCan be used as a module and from the command line.\n\n[![npm version][npm-badge]][npm-badge-url]\n[![Build Status][travis-badge]][travis-badge-url]\n[![Coverage Status][coveralls-badge]][coveralls-badge-url]\n[![Dependency Status][dev-badge]][dev-badge-url]\n\nSee the [CHANGELOG] for details about the latest release.\n\n## Features\n\n- Uses proper line endings on various operating systems\n- Handles double quotes\n- Allows custom column selection\n- Allows specifying nested properties\n- Reads column selection from file\n- Pretty writing to stdout\n- Supports optional custom delimiters\n- Supports optional custom eol value\n- Supports optional custom quotation marks\n- Optional header.\n- If field doesn't exist in object the field value in CSV will be empty.\n- Preserve new lines in values. Should be used with \\r\\n line endings for full compatibility with Excel.\n- Add a BOM character at the beginning of the csv to make Excel displaying special characters correctly.\n\n## How to install\n\nYou can install json2csv as a dependency using NPM.\n\n```bash\n# Global so it can be call from anywhere\n$ npm install -g json2csv\n# or as a dependency of a project\n$ npm install json2csv --save\n```\n\nAlso, if you are loading json2csv directly to the browser you can pull it directly from the CDN.\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/json2csv\"></script>\n```\n\nBy default, the above script will get the latest release of json2csv. You can also specify a specific version:\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/json2csv@4.2.1\"></script>\n```\n\n## Command Line Interface\n\n`json2csv` can be called from the command line if installed globally (using the `-g` flag).\n\n```bash\n  Usage: json2csv [options]\n\n\n  Options:\n\n    -V, --version                        output the version number\n    -i, --input <input>                  Path and name of the incoming json file. If not provided, will read from stdin.\n    -o, --output [output]                Path and name of the resulting csv file. Defaults to stdout.\n    -n, --ndjson                         Treat the input as NewLine-Delimited JSON.\n    -s, --no-streaming                   Process the whole JSON array in memory instead of doing it line by line.\n    -f, --fields <fields>                Specify the fields to convert.\n    -c, --fields-config <path>           Specify a file with a fields configuration as a JSON array.\n    -u, --unwind <paths>                 Creates multiple rows from a single JSON document similar to MongoDB unwind.\n    -B, --unwind-blank                   When unwinding, blank out instead of repeating data.\n    -F, --flatten                        Flatten nested objects.\n    -S, --flatten-separator <separator>  Flattened keys separator.\n    -v, --default-value [defaultValue]   Specify a default value other than empty string.\n    -q, --quote [value]                  Specify an alternate quote value.\n    -Q, --double-quote [value]           Specify a value to replace double quote in strings.\n    -d, --delimiter [delimiter]          Specify a delimiter other than the default comma to use.\n    -e, --eol [value]                    Specify an End-of-Line value for separating rows.\n    -E, --excel-strings                  Converts string data into normalized Excel style data.\n    -H, --no-header                      Disable the column name header.\n    -a, --include-empty-rows             Includes empty rows in the resulting CSV output.\n    -b, --with-bom                       Includes BOM character at the beginning of the csv.\n    -p, --pretty                         Use only when printing to console. Logs output in pretty tables.\n    -h, --help                           output usage information\n```\n\nIf no input `-i` is specified the result is expected from to the console standard input.\nIf no output `-o` is specified the result is printed to the console standard output.\nIf no fields `-f` or `-c` are passed the fields of the first element are used since json2csv CLI process the items one at a time. You can use the `--no-streaming` flag to load the entire JSON in memory and get all the headers. However, keep in mind that this is slower and requires much more memory.\nUse `-p` to show the result as a table in the console.\n\n### CLI examples\n\n#### Input file and specify fields\n\n```bash\n$ json2csv -i input.json -f carModel,price,color\ncarModel,price,color\n\"Audi\",10000,\"blue\"\n\"BMW\",15000,\"red\"\n\"Mercedes\",20000,\"yellow\"\n\"Porsche\",30000,\"green\"\n```\n\n#### Input file, specify fields and use pretty logging\n\n```bash\n$ json2csv -i input.json -f carModel,price,color -p\n```\n\n![Screenshot](https://s3.amazonaws.com/zeMirco/github/json2csv/json2csv-pretty.png)\n\n#### Generating CSV containing only specific fields\n\n```bash\n$ json2csv -i input.json -f carModel,price,color -o out.csv\n$ cat out.csv\ncarModel,price,color\n\"Audi\",10000,\"blue\"\n\"BMW\",15000,\"red\"\n\"Mercedes\",20000,\"yellow\"\n\"Porsche\",30000,\"green\"\n```\n\nSame result will be obtained passing the fields config as a file.\n\n```bash\n$ json2csv -i input.json -c fieldsConfig.json -o out.csv\n```\n\nwhere the file `fieldsConfig.json` contains\n\n```json\n[\n  \"carModel\",\n  \"price\",\n  \"color\"\n]\n```\n\n#### Read input from stdin\n\n```bash\n$ json2csv -f price\n[{\"price\":1000},{\"price\":2000}]\n```\n\nHit <kbd>Enter</kbd> and afterwards <kbd>CTRL</kbd> + <kbd>D</kbd> to end reading from stdin. The terminal should show\n\n```\nprice\n1000\n2000\n```\n\n#### Appending to existing CSV\n\nSometimes you want to add some additional rows with the same columns.\nThis is how you can do that.\n\n```bash\n# Initial creation of csv with headings\n$ json2csv -i test.json -f name,version > test.csv\n# Append additional rows\n$ json2csv -i test.json -f name,version --no-header >> test.csv\n```\n\n## Javascript module\n\n`json2csv` can also be use programatically from you javascript codebase.\n\n### Available Options\n\nThe programatic APIs take a configuration object very equivalent to the CLI options. \n\n- `fields` - Array of Objects/Strings. Defaults to toplevel JSON attributes. See example below.\n- `ndjson` - Only effective on the streaming API. Indicates that data coming through the stream is NDJSON.\n- `unwind` - Array of Strings, creates multiple rows from a single JSON document similar to MongoDB's $unwind\n- `unwindBlank` - Boolean, unwind using blank values instead of repeating data.\n- `flatten` - Boolean, flattens nested JSON using [flat]. Defaults to `false`.\n- `flattenSeparator` - String, separator to use between nested JSON keys when `flatten` option enabled. Defaults to `.` if not specified.\n- `defaultValue` - String, default value to use when missing data. Defaults to `<empty>` if not specified. (Overridden by `fields[].default`)\n- `quote` - String, quote around cell values and column names. Defaults to `\"` if not specified.\n- `doubleQuote` - String, the value to replace double quote in strings. Defaults to 2x`quotes` (for example `\"\"`) if not specified.\n- `delimiter` - String, delimiter of columns. Defaults to `,` if not specified.\n- `eol` - String, overrides the default OS line ending (i.e. `\\n` on Unix and `\\r\\n` on Windows).\n- `excelStrings` - Boolean, converts string data into normalized Excel style data.\n- `header` - Boolean, determines whether or not CSV file will contain a title column. Defaults to `true` if not specified.\n- `includeEmptyRows` - Boolean, includes empty rows. Defaults to `false`.\n- `withBOM` - Boolean, with BOM character. Defaults to `false`.\n\n### json2csv parser (Synchronous API)\n\n`json2csv` can also be use programatically as a synchronous converter using its `parse` method. \n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['field1', 'field2', 'field3'];\nconst opts = { fields };\n\ntry {\n  const parser = new Json2csvParser(opts);\n  const csv = parser.parse(myData);\n  console.log(csv);\n} catch (err) {\n  console.error(err);\n}\n```\n\nyou can also use the convenience method `parse`\n\n```javascript\nconst json2csv = require('json2csv').parse;\nconst fields = ['field1', 'field2', 'field3'];\nconst opts = { fields };\n\ntry {\n  const csv = json2csv(myData, opts);\n  console.log(csv);\n} catch (err) {\n  console.error(err);\n}\n```\n\n### json2csv transform (Streaming API)\n\nThe parse method is really good but has the downside of loading the entire JSON array in memory. This might not be optimal or even possible for large JSON files.\n\nFor such cases json2csv offers a stream transform so pipe your json content into it and it will output it.\n\nOne very important difference between the transform and the parser is that the json objects are processed one by one. In practice, this means that only the fields in the first object of the array are considered and fields in other other objects that were not present in the first one are just ignored. To avoid this. It's advisable to ensure that all the objects contain exactly the same fields or provide the list of fields using the `fields` option.\n\n```javascript\nconst fs = require('fs');\nconst Json2csvTransform = require('json2csv').Transform;\n\nconst fields = ['field1', 'field2', 'field3'];\nconst opts = { fields };\nconst transformOpts = { highWaterMark: 16384, encoding: 'utf-8' };\n\nconst input = fs.createReadStream(inputPath, { encoding: 'utf8' });\nconst output = fs.createWriteStream(outputPath, { encoding: 'utf8' });\nconst json2csv = new Json2csvTransform(opts, transformOpts);\n\nconst processor = input.pipe(json2csv).pipe(output);\n\n// You can also listen for events on the conversion and see how the header or the lines are coming out.\njson2csv\n  .on('header', header => console.log(header))\n  .on('line', line => console.log(line))\n  .on('error', err => console.log(err));\n```\n\nThe stream API can also work on object mode. This is useful when you have an input stream in object mode or if you are getting JSON objects one by one and want to convert them to CSV as they come.\n\n```javascript\n    const input = new Readable({ objectMode: true });\n    input._read = () => {};\n    // myObjectEmitter is just a fake example representing anything that emit objects.\n    myObjectEmitter.on('object', obj => input.push(obj));\n    // Pushing a null close the stream\n    myObjectEmitter.end(()) => input.push(null));\n\n    const opts = {};\n    const transformOpts = { objectMode: true };\n\n    const json2csv = new Json2csvTransform(opts, transformOpts);\n    const processor = input.pipe(transform).pipe(output);\n```\n\n### Javascript module examples\n\n#### Example `fields` option\n``` javascript\n{\n  fields: [\n    // Supports label -> simple path\n    {\n      label: 'some label', // (optional, column will be labeled 'path.to.something' if not defined)\n      value: 'path.to.something', // data.path.to.something\n      default: 'NULL' // default if value is not found (optional, overrides `defaultValue` for column)\n    },\n\n    // Supports label -> derived value\n    {\n      label: 'some label', // Supports duplicate labels (required, else your column will be labeled [function])\n      value: (row, field) => row.path1 + row.path2, // field = { label, default }\n      default: 'NULL', // default if value function returns null or undefined\n      stringify: true // If value is function use this flag to signal if resulting string will be quoted (stringified) or not (optional, default: true)\n    },\n\n    // Support pathname -> pathvalue\n    'simplepath', // equivalent to {value:'simplepath'}\n    'path.to.value' // also equivalent to {value:'path.to.value'}\n  ]\n}\n```\n\n#### Example 1\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['car', 'price', 'color'];\nconst myCars = [\n  {\n    \"car\": \"Audi\",\n    \"price\": 40000,\n    \"color\": \"blue\"\n  }, {\n    \"car\": \"BMW\",\n    \"price\": 35000,\n    \"color\": \"black\"\n  }, {\n    \"car\": \"Porsche\",\n    \"price\": 60000,\n    \"color\": \"green\"\n  }\n];\n\nconst json2csvParser = new Json2csvParser({ fields });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\nwill output to console\n\n```\ncar, price, color\n\"Audi\", 40000, \"blue\"\n\"BMW\", 35000, \"black\"\n\"Porsche\", 60000, \"green\"\n```\n\n#### Example 2\n\nSimilarly to [mongoexport](http://www.mongodb.org/display/DOCS/mongoexport) you can choose which fields to export.\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['car', 'color'];\n\nconst json2csvParser = new Json2csvParser({ fields });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\nResults in\n\n```\ncar, color\n\"Audi\", \"blue\"\n\"BMW\", \"black\"\n\"Porsche\", \"green\"\n```\n\n#### Example 3\n\nYou can choose custom column names for the exported file.\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = [{\n  label: 'Car Name',\n  value: 'car'\n},{\n  label: 'Price USD',\n  value: 'price'\n}];\n\nconst json2csvParser = new Json2csvParser({ fields });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\n#### Example 4\n\nYou can also specify nested properties using dot notation.\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['car.make', 'car.model', 'price', 'color'];\nconst myCars = [\n  {\n    \"car\": {\"make\": \"Audi\", \"model\": \"A3\"},\n    \"price\": 40000,\n    \"color\": \"blue\"\n  }, {\n    \"car\": {\"make\": \"BMW\", \"model\": \"F20\"},\n    \"price\": 35000,\n    \"color\": \"black\"\n  }, {\n    \"car\": {\"make\": \"Porsche\", \"model\": \"9PA AF1\"},\n    \"price\": 60000,\n    \"color\": \"green\"\n  }\n];\n\nconst json2csvParser = new Json2csvParser({ fields });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\nwill output to console\n\n```\ncar.make, car.model, price, color\n\"Audi\", \"A3\", 40000, \"blue\"\n\"BMW\", \"F20\", 35000, \"black\"\n\"Porsche\", \"9PA AF1\", 60000, \"green\"\n```\n\n#### Example 5\n\nUse a custom delimiter to create tsv files using the delimiter option:\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['car', 'price', 'color'];\n\nconst json2csvParser = new Json2csvParser({ fields, delimiter: '\\t' });\nconst tsv = json2csvParser.parse(myCars);\n\nconsole.log(tsv);\n```\n\nWill output:\n\n```\ncar price color\n\"Audi\"  10000 \"blue\"\n\"BMW\" 15000 \"red\"\n\"Mercedes\"  20000 \"yellow\"\n\"Porsche\" 30000 \"green\"\n```\n\nIf no delimiter is specified, the default `,` is used\n\n#### Example 6\n\nYou can choose custom quotation marks.\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = [{\n  label: 'Car Name',\n  value: 'car'\n},{\n  label: 'Price USD',\n  value: 'price'\n}];\n\nconst json2csvParser = new Json2csvParser({ fields, quote: '' });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\nResults in\n\n```\nCar Name, Price USD\nAudi, 10000\nBMW, 15000\nPorsche, 30000\n```\n\n#### Example 7\n\nYou can unwind arrays similar to MongoDB's $unwind operation using the `unwind` option.\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['carModel', 'price', 'colors'];\nconst myCars = [\n  {\n    \"carModel\": \"Audi\",\n    \"price\": 0,\n    \"colors\": [\"blue\",\"green\",\"yellow\"]\n  }, {\n    \"carModel\": \"BMW\",\n    \"price\": 15000,\n    \"colors\": [\"red\",\"blue\"]\n  }, {\n    \"carModel\": \"Mercedes\",\n    \"price\": 20000,\n    \"colors\": \"yellow\"\n  }, {\n    \"carModel\": \"Porsche\",\n    \"price\": 30000,\n    \"colors\": [\"green\",\"teal\",\"aqua\"]\n  }\n];\n\nconst json2csvParser = new Json2csvParser({ fields, unwind: 'colors' });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\nwill output to console\n\n```\n\"carModel\",\"price\",\"colors\"\n\"Audi\",0,\"blue\"\n\"Audi\",0,\"green\"\n\"Audi\",0,\"yellow\"\n\"BMW\",15000,\"red\"\n\"BMW\",15000,\"blue\"\n\"Mercedes\",20000,\"yellow\"\n\"Porsche\",30000,\"green\"\n\"Porsche\",30000,\"teal\"\n\"Porsche\",30000,\"aqua\"\n```\n\n#### Example 8\n\nYou can also unwind arrays multiple times or with nested objects.\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['carModel', 'price', 'items.name', 'items.color', 'items.items.position', 'items.items.color'];\nconst myCars = [\n  {\n    \"carModel\": \"BMW\",\n    \"price\": 15000,\n    \"items\": [\n      {\n        \"name\": \"airbag\",\n        \"color\": \"white\"\n      }, {\n        \"name\": \"dashboard\",\n        \"color\": \"black\"\n      }\n    ]\n  }, {\n    \"carModel\": \"Porsche\",\n    \"price\": 30000,\n    \"items\": [\n      {\n        \"name\": \"airbag\",\n        \"items\": [\n          {\n            \"position\": \"left\",\n            \"color\": \"white\"\n          }, {\n            \"position\": \"right\",\n            \"color\": \"gray\"\n          }\n        ]\n      }, {\n        \"name\": \"dashboard\",\n        \"items\": [\n          {\n            \"position\": \"left\",\n            \"color\": \"gray\"\n          }, {\n            \"position\": \"right\",\n            \"color\": \"black\"\n          }\n        ]\n      }\n    ]\n  }\n];\n\nconst json2csvParser = new Json2csvParser({ fields, unwind: ['items', 'items.items'] });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\nwill output to console\n\n```\n\"carModel\",\"price\",\"items.name\",\"items.color\",\"items.items.position\",\"items.items.color\"\n\"BMW\",15000,\"airbag\",\"white\",,\n\"BMW\",15000,\"dashboard\",\"black\",,\n\"Porsche\",30000,\"airbag\",,\"left\",\"white\"\n\"Porsche\",30000,\"airbag\",,\"right\",\"gray\"\n\"Porsche\",30000,\"dashboard\",,\"left\",\"gray\"\n\"Porsche\",30000,\"dashboard\",,\"right\",\"black\"\n```\n\n#### Example 9\n\nYou can also unwind arrays blanking the repeated fields.\n\n```javascript\nconst Json2csvParser = require('json2csv').Parser;\nconst fields = ['carModel', 'price', 'items.name', 'items.color', 'items.items.position', 'items.items.color'];\nconst myCars = [\n  {\n    \"carModel\": \"BMW\",\n    \"price\": 15000,\n    \"items\": [\n      {\n        \"name\": \"airbag\",\n        \"color\": \"white\"\n      }, {\n        \"name\": \"dashboard\",\n        \"color\": \"black\"\n      }\n    ]\n  }, {\n    \"carModel\": \"Porsche\",\n    \"price\": 30000,\n    \"items\": [\n      {\n        \"name\": \"airbag\",\n        \"items\": [\n          {\n            \"position\": \"left\",\n            \"color\": \"white\"\n          }, {\n            \"position\": \"right\",\n            \"color\": \"gray\"\n          }\n        ]\n      }, {\n        \"name\": \"dashboard\",\n        \"items\": [\n          {\n            \"position\": \"left\",\n            \"color\": \"gray\"\n          }, {\n            \"position\": \"right\",\n            \"color\": \"black\"\n          }\n        ]\n      }\n    ]\n  }\n];\n\nconst json2csvParser = new Json2csvParser({ fields, unwind: ['items', 'items.items'], unwindBlank: true });\nconst csv = json2csvParser.parse(myCars);\n\nconsole.log(csv);\n```\n\nwill output to console\n\n```\n\"carModel\",\"price\",\"items.name\",\"items.color\",\"items.items.position\",\"items.items.color\"\n\"BMW\",15000,\"airbag\",\"white\",,\n,,\"dashboard\",\"black\",,\n\"Porsche\",30000,\"airbag\",,\"left\",\"white\"\n,,,,\"right\",\"gray\"\n,,\"dashboard\",,\"left\",\"gray\"\n,,,,\"right\",\"black\"\n```\n\n### Migrating from 3.X to 4.X\n\nWhat in 3.X used to be\n```\nconst json2csv = require('json2csv');\nconst csv = json2csv({ data: myData, fields: myFields, unwindPath: paths, ... });\n```\n\ncan be replaced by\n```\nconst Json2csvParser = require('json2csv').Parser;\nconst json2csvParser = new Json2csvParser({ fields: myFields, unwind: paths, ... });\nconst csv = json2csvParser.parse(myData);\n```\n\nor the convenience method\n```\nconst json2csv = require('json2csv');\nconst csv = json2csv.parse(myData, { fields: myFields, unwind: paths, ... });\n```\n\nPlease note that many of the configuration parameters have been slightly renamed. Please check one by one that all your parameters are correct.\nYou can se the documentation for json2csv 3.11.5 [here](https://github.com/zemirco/json2csv/blob/v3.11.5/README.md).\n\n## Building\n\nWhen developing, it's necessary to run `webpack` to prepare the built script. This can be done easily with `npm run build`.\n\nIf `webpack` is not already available from the command line, use `npm install -g webpack`.\n\n## Testing\n\nRun the folowing command to check the code style.\n\n```bash\n$ npm run lint\n```\n\nRun the following command to run the tests and return coverage\n\n```bash\n$ npm run test-with-coverage\n```\n\n## Contributors\n\nAfter you clone the repository you just need to install the required packages for development by runnning following command under json2csv dir.\n\n```bash\n$ npm install\n```\n\nBefore making any pull request please ensure sure that your code is formatted, test are passing and test coverage haven't decreased. (See [Testing](#testing))\n\n## Similar Projects\n\n* [Papa Parse](http://papaparse.com/)\n\n## License\n\nSee [LICENSE.md].\n\n[npm-badge]: https://badge.fury.io/js/json2csv.svg\n[npm-badge-url]: http://badge.fury.io/js/json2csv\n[travis-badge]: https://travis-ci.org/zemirco/json2csv.svg\n[travis-badge-url]: https://travis-ci.org/zemirco/json2csv\n[coveralls-badge]: https://coveralls.io/repos/zemirco/json2csv/badge.svg?branch=master\n[coveralls-badge-url]: https://coveralls.io/r/zemirco/json2csv?branch=master\n[dev-badge]: https://david-dm.org/zemirco/json2csv.svg\n[dev-badge-url]: https://david-dm.org/zemirco/json2csv\n[CHANGELOG]: https://github.com/zemirco/json2csv/blob/master/CHANGELOG.md\n[LICENSE.md]: https://github.com/zemirco/json2csv/blob/master/LICENSE.md\n[flat]: https://www.npmjs.com/package/flat\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/zemirco/json2csv.git"
  },
  "scripts": {
    "before:publish": "npm test && npm run build && npm run deploy:docs",
    "build": "rollup -c",
    "coveralls": "nyc report --reporter=text-lcov | coveralls",
    "deploy:docs": "docpress b && gh-pages -d _docpress",
    "dev": "rollup -c -w",
    "lint": "eslint bin lib test",
    "prepublish": "in-publish && npm run before:publish || not-in-publish",
    "release": "standard-version",
    "test": "node test | tap-spec",
    "test-with-coverage": "nyc --reporter=text node test | tap-spec"
  },
  "version": "4.3.2"
}
